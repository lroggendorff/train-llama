{
  "batch-size": 16,
  "epochs": 3,
  "learning-rate": 0.0002,
  "max-seq-length": 512,
  "vocab-size": 32000,
  "fp16": true,
  "weight-decay": 0.001,
  "gradient-accumulation-steps": 4,
  "input-dataset": "HuggingFaceTB/smollm-corpus",
  "instruct-dataset": "nroggendorff/elephant",
  "shard-size": 200000,
  "output-repo": "nroggendorff/smallama",
  "push-to-hub": true,
  "instruct-finetune-bool": false,
  "factor": 1728,
  "total-steps": 375,
  "warmup-steps": 37,
  "init": 0
}